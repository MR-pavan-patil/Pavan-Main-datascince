{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f057de",
   "metadata": {},
   "source": [
    "# Generated Exercise Notebook\n",
    "\n",
    "**Source dataset:** `be192d6b-2a99-44a6-b829-f7922726520e.csv`  \n",
    "Rows: **10000**, Columns: **8**  \n",
    "\n",
    "**Columns:** ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "**Numeric columns:** []\n",
    "\n",
    "**Categorical columns:** ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "---\n",
    "\n",
    "Open each question cell, run the starter code, and finish the required steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd698175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"/mnt/data/be192d6b-2a99-44a6-b829-f7922726520e.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4444a0",
   "metadata": {},
   "source": [
    "## Question 1 — Basic dataset overview\n",
    "\n",
    "Write code to show:\n",
    "- `.info()`\n",
    "- number of missing values per column\n",
    "- basic descriptive statistics for numeric columns\n",
    "Explain any observations in a markdown cell below the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print('\\nMissing values per column:\\n', df.isnull().sum())\n",
    "print('\\nDescriptive statistics:\\n', df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37678c9a",
   "metadata": {},
   "source": [
    "## Question 2 — Data types and conversion\n",
    "\n",
    "Identify columns with incorrect data types (e.g., numeric stored as object). Convert at least one such column to the appropriate dtype and verify conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cab17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "# Example conversion (replace 'colname' with actual column):\n",
    "# df['colname'] = pd.to_numeric(df['colname'], errors='coerce')\n",
    "# df['datecol'] = pd.to_datetime(df['datecol'], errors='coerce')\n",
    "# Verify:\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff546f6a",
   "metadata": {},
   "source": [
    "## Question 3 — Duplicates & unique values\n",
    "\n",
    "Detect duplicate rows and drop them if appropriate. For each categorical column, show the number of unique values and the top 5 frequent categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Duplicate rows:', df.duplicated().sum())\n",
    "# df = df.drop_duplicates()\n",
    "for c in df.select_dtypes(include=['object','category']).columns:\n",
    "    print('\\nColumn:', c)\n",
    "    print('Unique values:', df[c].nunique())\n",
    "    print('Top 5 frequent:')\n",
    "    print(df[c].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1cb27",
   "metadata": {},
   "source": [
    "## Question 4 — Handling missing values\n",
    "\n",
    "Choose a missing-value strategy for each column with missing data (drop, fill with mean/median/mode, forward/backward fill). Implement the chosen strategy and show before/after counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example strategies. Replace with chosen strategies\n",
    "missing = df.isnull().sum()[df.isnull().sum()>0]\n",
    "print('Columns with missing values:\\n', missing)\n",
    "# Example:\n",
    "# df['num_col'] = df['num_col'].fillna(df['num_col'].median())\n",
    "# df['cat_col'] = df['cat_col'].fillna(df['cat_col'].mode()[0])\n",
    "# Verify:\n",
    "# print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffecad7",
   "metadata": {},
   "source": [
    "## Question 5 — Exploratory plotting\n",
    "\n",
    "Create at least three plots that help understand the dataset:\n",
    "- Histogram or KDE for numeric columns\n",
    "- Boxplot to spot outliers\n",
    "- Bar chart for a categorical column\n",
    "Include brief interpretation of each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Example histogram for numeric columns\n",
    "for c in df.select_dtypes(include=['number']).columns[:3]:\n",
    "    plt.figure()\n",
    "    df[c].hist()\n",
    "    plt.title(f'Histogram of {c}')\n",
    "\n",
    "# Example boxplot\n",
    "for c in df.select_dtypes(include=['number']).columns[:3]:\n",
    "    plt.figure()\n",
    "    df.boxplot(column=c)\n",
    "    plt.title(f'Boxplot of {c}')\n",
    "\n",
    "# Bar chart for first categorical column\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "if len(cat_cols)>0:\n",
    "    plt.figure()\n",
    "    df[cat_cols[0]].value_counts().head(10).plot(kind='bar')\n",
    "    plt.title(f'Top categories in {cat_cols[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce973e8",
   "metadata": {},
   "source": [
    "## Question 6 — Outliers\n",
    "\n",
    "Detect outliers in numeric columns using the IQR method. Propose and implement one method to handle them (cap, remove, or transform). Show effect on distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa769ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_filter(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low = Q1 - 1.5*IQR\n",
    "    high = Q3 + 1.5*IQR\n",
    "    return low, high\n",
    "\n",
    "for c in df.select_dtypes(include=['number']).columns[:4]:\n",
    "    low, high = iqr_filter(df[c].dropna())\n",
    "    print(c, 'low', low, 'high', high)\n",
    "    print('Outliers count:', ((df[c] < low)|(df[c] > high)).sum())\n",
    "\n",
    "# Example capping:\n",
    "# df[c] = df[c].clip(lower=low, upper=high)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39dd12f",
   "metadata": {},
   "source": [
    "## Question 7 — Correlation analysis\n",
    "\n",
    "Compute pairwise correlation for numeric features and visualize it (heatmap). Identify any strong correlations (>|0.7|)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "corr = df.select_dtypes(include=['number']).corr()\n",
    "print(corr)\n",
    "plt.figure(figsize=(8,6))\n",
    "import numpy as np\n",
    "plt.imshow(corr, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr)), corr.columns)\n",
    "plt.title('Correlation matrix (visual)')\n",
    "\n",
    "# Identify strong correlations\n",
    "strong = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        if abs(corr.iloc[i,j]) > 0.7:\n",
    "            strong.append((corr.columns[i], corr.columns[j], corr.iloc[i,j]))\n",
    "print('Strong correlations > 0.7:', strong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7748d471",
   "metadata": {},
   "source": [
    "## Question 8 — Feature engineering\n",
    "\n",
    "Create at least two new features from existing columns (example: ratio, interaction term, datetime parts). Show code and rationale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8af49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: if there are numeric columns 'a' and 'b'\n",
    "# df['a_to_b_ratio'] = df['a'] / (df['b'] + 1e-9)\n",
    "# If a datetime column exists: df['month'] = pd.to_datetime(df['datecol']).dt.month\n",
    "\n",
    "# Print head to show new features\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b7f2e",
   "metadata": {},
   "source": [
    "## Question 9 — Encoding categorical variables\n",
    "\n",
    "Encode categorical variables using appropriate techniques (one-hot, label encoding, target encoding). Provide code and explanation for choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "print('Categorical columns:', cat_cols)\n",
    "# Example label encoding:\n",
    "# le = LabelEncoder()\n",
    "# df['col_le'] = le.fit_transform(df['col'])\n",
    "# Example one-hot:\n",
    "# df = pd.get_dummies(df, columns=['col1','col2'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af44989",
   "metadata": {},
   "source": [
    "## Question 10 — Build a simple model\n",
    "\n",
    "Identify a suitable target column (suggestion: ['Transaction Date']). Split data into train/test, train a simple model (e.g., LogisticRegression for classification or LinearRegression for regression), evaluate using appropriate metrics, and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example starter (replace 'target' with actual target column):\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Prepare X, y (this is a placeholder — replace with proper preprocessing)\n",
    "# y = df['target']\n",
    "# X = df.drop(columns=['target'])\n",
    "# X = pd.get_dummies(X, drop_first=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# If classification:\n",
    "# model = LogisticRegression(max_iter=1000)\n",
    "# model.fit(X_train, y_train)\n",
    "# preds = model.predict(X_test)\n",
    "# print('Accuracy:', accuracy_score(y_test, preds))\n",
    "\n",
    "# If regression:\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# preds = model.predict(X_test)\n",
    "# print('RMSE:', mean_squared_error(y_test, preds, squared=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1a17c",
   "metadata": {},
   "source": [
    "## Question 11 — Model tuning & validation\n",
    "\n",
    "Perform cross-validation and simple hyperparameter tuning (GridSearchCV or RandomizedSearchCV) on the model from Q10. Report the best parameters and CV score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b90241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example starter:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {'C':[0.01,0.1,1,10]}\n",
    "# grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "# print(grid.best_params_, grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c2f84f",
   "metadata": {},
   "source": [
    "## Question 12 — Reproducibility & report\n",
    "\n",
    "Save the final cleaned dataset to a CSV (`cleaned_data.csv`), and write a short markdown summary (3-5 bullet points) describing the key findings and the modeling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example save:\n",
    "# df.to_csv('cleaned_data.csv', index=False)\n",
    "# Print a template for the summary:\n",
    "print('Write 3-5 bullet points summarizing findings and model performance here.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
