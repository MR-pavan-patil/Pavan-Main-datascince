{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f057de",
   "metadata": {},
   "source": [
    "# Generated Exercise Notebook\n",
    "\n",
    "**Source dataset:** `be192d6b-2a99-44a6-b829-f7922726520e.csv`  \n",
    "Rows: **10000**, Columns: **8**  \n",
    "\n",
    "**Columns:** ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "**Numeric columns:** []\n",
    "\n",
    "**Categorical columns:** ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
    "\n",
    "---\n",
    "\n",
    "Open each question cell, run the starter code, and finish the required steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd698175",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/be192d6b-2a99-44a6-b829-f7922726520e.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/mnt/data/be192d6b-2a99-44a6-b829-f7922726520e.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/mnt/data/be192d6b-2a99-44a6-b829-f7922726520e.csv'"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"/mnt/data/be192d6b-2a99-44a6-b829-f7922726520e.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4444a0",
   "metadata": {},
   "source": [
    "## Question 1 — Basic dataset overview\n",
    "\n",
    "Write code to show:\n",
    "- `.info()`\n",
    "- number of missing values per column\n",
    "- basic descriptive statistics for numeric columns\n",
    "Explain any observations in a markdown cell below the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print('\\nMissing values per column:\\n', df.isnull().sum())\n",
    "print('\\nDescriptive statistics:\\n', df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37678c9a",
   "metadata": {},
   "source": [
    "## Question 2 — Data types and conversion\n",
    "\n",
    "Identify columns with incorrect data types (e.g., numeric stored as object). Convert at least one such column to the appropriate dtype and verify conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cab17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "# Example conversion (replace 'colname' with actual column):\n",
    "# df['colname'] = pd.to_numeric(df['colname'], errors='coerce')\n",
    "# df['datecol'] = pd.to_datetime(df['datecol'], errors='coerce')\n",
    "# Verify:\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff546f6a",
   "metadata": {},
   "source": [
    "## Question 3 — Duplicates & unique values\n",
    "\n",
    "Detect duplicate rows and drop them if appropriate. For each categorical column, show the number of unique values and the top 5 frequent categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Duplicate rows:', df.duplicated().sum())\n",
    "# df = df.drop_duplicates()\n",
    "for c in df.select_dtypes(include=['object','category']).columns:\n",
    "    print('\\nColumn:', c)\n",
    "    print('Unique values:', df[c].nunique())\n",
    "    print('Top 5 frequent:')\n",
    "    print(df[c].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1cb27",
   "metadata": {},
   "source": [
    "## Question 4 — Handling missing values\n",
    "\n",
    "Choose a missing-value strategy for each column with missing data (drop, fill with mean/median/mode, forward/backward fill). Implement the chosen strategy and show before/after counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example strategies. Replace with chosen strategies\n",
    "missing = df.isnull().sum()[df.isnull().sum()>0]\n",
    "print('Columns with missing values:\\n', missing)\n",
    "# Example:\n",
    "# df['num_col'] = df['num_col'].fillna(df['num_col'].median())\n",
    "# df['cat_col'] = df['cat_col'].fillna(df['cat_col'].mode()[0])\n",
    "# Verify:\n",
    "# print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffecad7",
   "metadata": {},
   "source": [
    "## Question 5 — Exploratory plotting\n",
    "\n",
    "Create at least three plots that help understand the dataset:\n",
    "- Histogram or KDE for numeric columns\n",
    "- Boxplot to spot outliers\n",
    "- Bar chart for a categorical column\n",
    "Include brief interpretation of each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Example histogram for numeric columns\n",
    "for c in df.select_dtypes(include=['number']).columns[:3]:\n",
    "    plt.figure()\n",
    "    df[c].hist()\n",
    "    plt.title(f'Histogram of {c}')\n",
    "\n",
    "# Example boxplot\n",
    "for c in df.select_dtypes(include=['number']).columns[:3]:\n",
    "    plt.figure()\n",
    "    df.boxplot(column=c)\n",
    "    plt.title(f'Boxplot of {c}')\n",
    "\n",
    "# Bar chart for first categorical column\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "if len(cat_cols)>0:\n",
    "    plt.figure()\n",
    "    df[cat_cols[0]].value_counts().head(10).plot(kind='bar')\n",
    "    plt.title(f'Top categories in {cat_cols[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce973e8",
   "metadata": {},
   "source": [
    "## Question 6 — Outliers\n",
    "\n",
    "Detect outliers in numeric columns using the IQR method. Propose and implement one method to handle them (cap, remove, or transform). Show effect on distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa769ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_filter(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low = Q1 - 1.5*IQR\n",
    "    high = Q3 + 1.5*IQR\n",
    "    return low, high\n",
    "\n",
    "for c in df.select_dtypes(include=['number']).columns[:4]:\n",
    "    low, high = iqr_filter(df[c].dropna())\n",
    "    print(c, 'low', low, 'high', high)\n",
    "    print('Outliers count:', ((df[c] < low)|(df[c] > high)).sum())\n",
    "\n",
    "# Example capping:\n",
    "# df[c] = df[c].clip(lower=low, upper=high)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39dd12f",
   "metadata": {},
   "source": [
    "## Question 7 — Correlation analysis\n",
    "\n",
    "Compute pairwise correlation for numeric features and visualize it (heatmap). Identify any strong correlations (>|0.7|)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "corr = df.select_dtypes(include=['number']).corr()\n",
    "print(corr)\n",
    "plt.figure(figsize=(8,6))\n",
    "import numpy as np\n",
    "plt.imshow(corr, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr)), corr.columns)\n",
    "plt.title('Correlation matrix (visual)')\n",
    "\n",
    "# Identify strong correlations\n",
    "strong = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        if abs(corr.iloc[i,j]) > 0.7:\n",
    "            strong.append((corr.columns[i], corr.columns[j], corr.iloc[i,j]))\n",
    "print('Strong correlations > 0.7:', strong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7748d471",
   "metadata": {},
   "source": [
    "## Question 8 — Feature engineering\n",
    "\n",
    "Create at least two new features from existing columns (example: ratio, interaction term, datetime parts). Show code and rationale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8af49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: if there are numeric columns 'a' and 'b'\n",
    "# df['a_to_b_ratio'] = df['a'] / (df['b'] + 1e-9)\n",
    "# If a datetime column exists: df['month'] = pd.to_datetime(df['datecol']).dt.month\n",
    "\n",
    "# Print head to show new features\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b7f2e",
   "metadata": {},
   "source": [
    "## Question 9 — Encoding categorical variables\n",
    "\n",
    "Encode categorical variables using appropriate techniques (one-hot, label encoding, target encoding). Provide code and explanation for choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "print('Categorical columns:', cat_cols)\n",
    "# Example label encoding:\n",
    "# le = LabelEncoder()\n",
    "# df['col_le'] = le.fit_transform(df['col'])\n",
    "# Example one-hot:\n",
    "# df = pd.get_dummies(df, columns=['col1','col2'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af44989",
   "metadata": {},
   "source": [
    "## Question 10 — Build a simple model\n",
    "\n",
    "Identify a suitable target column (suggestion: ['Transaction Date']). Split data into train/test, train a simple model (e.g., LogisticRegression for classification or LinearRegression for regression), evaluate using appropriate metrics, and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example starter (replace 'target' with actual target column):\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Prepare X, y (this is a placeholder — replace with proper preprocessing)\n",
    "# y = df['target']\n",
    "# X = df.drop(columns=['target'])\n",
    "# X = pd.get_dummies(X, drop_first=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# If classification:\n",
    "# model = LogisticRegression(max_iter=1000)\n",
    "# model.fit(X_train, y_train)\n",
    "# preds = model.predict(X_test)\n",
    "# print('Accuracy:', accuracy_score(y_test, preds))\n",
    "\n",
    "# If regression:\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# preds = model.predict(X_test)\n",
    "# print('RMSE:', mean_squared_error(y_test, preds, squared=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1a17c",
   "metadata": {},
   "source": [
    "## Question 11 — Model tuning & validation\n",
    "\n",
    "Perform cross-validation and simple hyperparameter tuning (GridSearchCV or RandomizedSearchCV) on the model from Q10. Report the best parameters and CV score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b90241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example starter:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {'C':[0.01,0.1,1,10]}\n",
    "# grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "# print(grid.best_params_, grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c2f84f",
   "metadata": {},
   "source": [
    "## Question 12 — Reproducibility & report\n",
    "\n",
    "Save the final cleaned dataset to a CSV (`cleaned_data.csv`), and write a short markdown summary (3-5 bullet points) describing the key findings and the modeling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example save:\n",
    "# df.to_csv('cleaned_data.csv', index=False)\n",
    "# Print a template for the summary:\n",
    "print('Write 3-5 bullet points summarizing findings and model performance here.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
